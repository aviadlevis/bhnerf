{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ca7d61-9108-47e2-90b0-b589975a9040",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial5: visualize recovery results\n",
    "\n",
    "---\n",
    "This tutorial demonstrates visualize the 3D / 4D recovery results. \\\n",
    "By sampling a trained neural network at regular grid intervals we can visualize the recovered 3D emission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbf1765c-890a-4c7a-a16d-c8a64b217f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from flax.training import checkpoints\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "94cdafee-51cc-49b0-a821-030de4430aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "bhnerf methods\n",
    "\"\"\"\n",
    "from flax import linen as nn\n",
    "from typing import Any, Callable\n",
    "import jax, flax\n",
    "from jax import numpy as jnp\n",
    "from astropy import units\n",
    "import functools\n",
    "\n",
    "from astropy.constants import M_sun\n",
    "sgra_mass = 4.154*10**6 * M_sun\n",
    "\n",
    "normalize = lambda vector: vector / np.sqrt(np.dot(vector, vector))\n",
    "safe_sin = lambda x: jnp.sin(x % (100 * jnp.pi))\n",
    "\n",
    "class NeRF_Predictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Full function to predict emission at a time step.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    posenc_deg: int, default=3\n",
    "    net_depth: int, default=4\n",
    "    net_width: int, default=128\n",
    "    activation: Callable[..., Any], default=nn.relu\n",
    "    out_channel: int default=1\n",
    "    do_skip: bool, default=True\n",
    "    \"\"\"\n",
    "    posenc_deg: int = 3\n",
    "    net_depth: int = 4\n",
    "    net_width: int = 128\n",
    "    activation: Callable[..., Any] = nn.relu\n",
    "    out_channel: int = 1\n",
    "    do_skip: bool = True\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, t_frames, t_units, coords, Omega, t_start_obs, t_geos, t_injection):\n",
    "        \"\"\"\n",
    "        Sample emission on given coordinates at specified times assuming a velocity model (Omega)\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        t_frames: array, \n",
    "            Array of time for each image frame\n",
    "        t_units: astropy.units, \n",
    "            Time units of t_frames.\n",
    "        coords: list of arrays, \n",
    "            For 3D emission coords=[x, y, z] with each array shape=(nt, num_alpha, num_beta, ngeo)\n",
    "            alpha, beta are image coordinates. These arrays contain the ray integration points\n",
    "        Omega: array, \n",
    "            Angular velocity array sampled along the coords points\n",
    "        t_start_obs: astropy.Quantity, default=None\n",
    "            Start time for observations, if None t_frames[0] is assumed to be start time.\n",
    "        t_geos: array, \n",
    "            Time along each geodesic (ray). This is used to account for slow light (light travels at finite velocity).\n",
    "        t_injection: float, \n",
    "            Time of hotspot injection in M units.\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        emission: jnp.array,\n",
    "            An array with the emission points\n",
    "        \"\"\"\n",
    "        emission_MLP = MLP(self.net_depth, self.net_width, self.activation, self.out_channel, self.do_skip)\n",
    "        def predict_emission(t_frames, t_units, coords, Omega, t_start_obs, t_geos, t_injection):\n",
    "            warped_coords = velocity_warp_coords(\n",
    "                coords, Omega, t_frames, t_start_obs, t_geos, t_injection, t_units=t_units, use_jax=True\n",
    "            )\n",
    "            \n",
    "            # Zero emission prior to injection time\n",
    "            valid_inputs_mask = jnp.isfinite(warped_coords)\n",
    "            net_input = jnp.where(valid_inputs_mask, warped_coords, jnp.zeros_like(warped_coords))\n",
    "            net_output = emission_MLP(posenc(net_input, self.posenc_deg))\n",
    "            emission = nn.sigmoid(net_output[..., 0] - 10.0)\n",
    "            emission = jnp.where(valid_inputs_mask[..., 0], emission, jnp.zeros_like(emission))\n",
    "            \n",
    "            return emission\n",
    "        \n",
    "        t_injection_param = self.param('t_injection', lambda key, values: jnp.array(values, dtype=jnp.float32), t_injection)\n",
    "        emission = predict_emission(t_frames, t_units, coords, Omega, t_start_obs, t_geos, t_injection_param)\n",
    "        return emission\n",
    "    \n",
    "class MLP(nn.Module):\n",
    "    net_depth: int = 4\n",
    "    net_width: int = 128\n",
    "    activation: Callable[..., Any] = nn.relu\n",
    "    out_channel: int = 1\n",
    "    do_skip: bool = True\n",
    "  \n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        \"\"\"A simple Multi-Layer Preceptron (MLP) network\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: jnp.ndarray(float32), \n",
    "            [batch_size * n_samples, feature], points.\n",
    "        net_depth: int, \n",
    "            the depth of the first part of MLP.\n",
    "        net_width: int, \n",
    "            the width of the first part of MLP.\n",
    "        activation: function, \n",
    "            the activation function used in the MLP.\n",
    "        out_channel: \n",
    "            int, the number of alpha_channels.\n",
    "        do_skip: boolean, \n",
    "            whether or not to use a skip connection\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        out: jnp.ndarray(float32), \n",
    "            [batch_size * n_samples, out_channel].\n",
    "        \"\"\"\n",
    "        dense_layer = functools.partial(\n",
    "            nn.Dense, kernel_init=jax.nn.initializers.he_uniform())\n",
    "\n",
    "        if self.do_skip:\n",
    "            skip_layer = self.net_depth // 2\n",
    "\n",
    "        inputs = x\n",
    "        for i in range(self.net_depth):\n",
    "            x = dense_layer(self.net_width)(x)\n",
    "            x = self.activation(x)\n",
    "            if self.do_skip:\n",
    "                if i % skip_layer == 0 and i > 0:\n",
    "                    x = jnp.concatenate([x, inputs], axis=-1)\n",
    "        out = dense_layer(self.out_channel)(x)\n",
    "\n",
    "        return out\n",
    "    \n",
    "def velocity_warp_coords(coords, Omega, t_frames, t_start_obs, t_geos, t_injection, rot_axis=[0,0,1], M=sgra_mass, t_units=None, use_jax=False):\n",
    "    \"\"\"\n",
    "    Generate an coordinate transoform for the velocity warp.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    coords: list of np arrays\n",
    "        A list of arrays with grid coordinates\n",
    "    Omega: array, \n",
    "        Angular velocity array sampled along the coords points.\n",
    "    t_frames: array, \n",
    "        Array of time for each image frame with astropy.units\n",
    "    t_start_obs: astropy.Quantity, default=None\n",
    "        Start time for observations, if None t_frames[0] is assumed to be start time.\n",
    "    t_geos: array, \n",
    "        Time along each geodesic (ray). This is used to account for slow light (light travels at finite velocity).\n",
    "    t_injection: float, \n",
    "        Time of hotspot injection in M units.\n",
    "    rot_axis: array, default=[0, 0, 1]\n",
    "        Currently only equitorial plane rotation is supported\n",
    "    M: astropy.Quantity, default=constants.sgra_mass,\n",
    "        Mass of the black hole used to convert frame times to space-time times in units of M\n",
    "    t_units: astropy.units, default=None,\n",
    "        Time units. If None units are taken from t_frames.\n",
    "    use_jax: bool, default=False,\n",
    "        Using jax enables GPU accelerated computing.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    warped_coords: array,\n",
    "        An array with the new coordinates for the warp transformation.\n",
    "    \"\"\"\n",
    "    _np = jnp if use_jax else np\n",
    "    coords = _np.array(coords)\n",
    "    Omega = _np.array(Omega)\n",
    "    \n",
    "    if isinstance(t_start_obs, units.Quantity):\n",
    "        t_units = t_start_obs.unit\n",
    "        t_start_obs = t_start_obs.value\n",
    "    \n",
    "    GM_c3 = 1.0  \n",
    "    if t_units is not None:\n",
    "        GM_c3 = consts.GM_c3(M).to(t_units).value\n",
    "\n",
    "    if isinstance(t_frames, units.Quantity):\n",
    "        t_frames = t_frames.to(t_units).value\n",
    "    t_frames = _np.array(t_frames)\n",
    "\n",
    "    if (_np.isscalar(Omega) or Omega.ndim == 0):\n",
    "        Omega = expand_dims(Omega, coords.ndim-1, axis=-1, use_jax=use_jax)\n",
    "\n",
    "    # Extend the dimensions of `t_frames` and `coords' for an array of times \n",
    "    if not (t_frames.ndim == 0):\n",
    "        coords = expand_dims(coords, coords.ndim + t_frames.ndim, 1, use_jax)\n",
    "        t_frames = expand_dims(t_frames, t_frames.ndim + Omega.ndim, -1, use_jax)\n",
    "\n",
    "    # Convert time units to grid units\n",
    "    \n",
    "    t_geos = (t_frames - t_start_obs)/GM_c3 + _np.array(t_geos)\n",
    "    t_M = t_geos - t_injection\n",
    "    \n",
    "    # Insert nans for angles before the injection time\n",
    "    theta_rot = _np.array(t_M * Omega)\n",
    "    theta_rot = _np.where(t_M < 0.0, _np.full_like(theta_rot, fill_value=np.nan), theta_rot)\n",
    "\n",
    "    inv_rot_matrix = rotation_matrix(rot_axis, -theta_rot, use_jax=use_jax)\n",
    "        \n",
    "    warped_coords = _np.sum(inv_rot_matrix * coords, axis=1)\n",
    "    warped_coords = _np.moveaxis(warped_coords, 0, -1)\n",
    "    return warped_coords\n",
    "\n",
    "def sample_3d_grid(apply_fn, params, rmin=0.0, rmax=np.inf, fov=None, coords=None, resolution=64): \n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    apply_fn: nn.Module\n",
    "        A coordinate-based neural net for predicting the emission values as a continuous function\n",
    "    params: dict, \n",
    "        A dictionary with network parameters (from state.params)\n",
    "    rmin: float, default=0\n",
    "        Zero values at radii < rmin\n",
    "    rmax: float, default=np.inf\n",
    "        Zero values at radii > rmax,\n",
    "    fov: float, default=None\n",
    "        Field of view. If None then coords need to be provided.\n",
    "    coords: array(shape=(3,npoints)), optional, \n",
    "        Array of grid coordinates (x, y, z). If not specified, fov and resolution are used to grid the domain.\n",
    "    resolution: int, default=64\n",
    "        Grid resolution along [x,y,z].\n",
    "    \"\"\"     \n",
    "    try:\n",
    "        params = jax.device_get(flax.jax_utils.unreplicate(params))\n",
    "    except IndexError:\n",
    "        params = jax.device_get(params)\n",
    "    \n",
    "    if (coords is None) and (fov is not None):\n",
    "        grid_1d = np.linspace(-fov/2, fov/2, resolution)\n",
    "        coords = np.array(np.meshgrid(grid_1d, grid_1d, grid_1d, indexing='ij'))\n",
    "    elif (coords is None):\n",
    "        raise AttributeError('Either coords or fov+resolution must be provided')\n",
    "\n",
    "    # Get the a grid values sampled from the neural network\n",
    "    emission = apply_fn({'params': params}, 0.0, None, coords, 0.0, 0.0, 0.0, 0.0)\n",
    "    emission =  fill_unsupervised_emission(emission, coords, rmin, rmax)\n",
    "    return emission\n",
    "\n",
    "def fill_unsupervised_emission(emission, coords, rmin=0, rmax=np.Inf, fill_value=0.0, use_jax=False):\n",
    "    \"\"\"\n",
    "    Fill emission that is not within the supervision region\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    emission: np.array\n",
    "        3D array with emission values\n",
    "    coords: list of np.arrays\n",
    "        Spatial coordinate arrays each shaped like emission\n",
    "    rmin: float, default=0\n",
    "        Zero values at radii < rmin\n",
    "    rmax: float, default=np.inf\n",
    "        Zero values at radii > rmax\n",
    "    fill_value: float, default=0.0\n",
    "        Fill value is default to zero \n",
    "    use_jax: bool, default=False,\n",
    "        Using jax enables GPU accelerated computing.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    emission: np.array\n",
    "        3D array with emission values filled in\n",
    "    \"\"\"\n",
    "    _np = jnp if use_jax else np\n",
    "    r_sq = _np.sum(_np.array([_np.squeeze(x)**2 for x in coords]), axis=0)\n",
    "    emission = _np.where(r_sq < rmin**2, _np.full_like(emission, fill_value=fill_value), emission)\n",
    "    emission = _np.where(r_sq > rmax**2, _np.full_like(emission, fill_value=fill_value), emission)\n",
    "    return emission\n",
    "\n",
    "def rotation_matrix(axis, angle, use_jax=False):\n",
    "    \"\"\"\n",
    "    Return the rotation matrix associated with counterclockwise rotation about\n",
    "    the given axis\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    axis: list or np.array, dim=3\n",
    "        Axis of rotation\n",
    "    angle: float or numpy array of floats,\n",
    "        Angle of rotation in radians\n",
    "    use_jax: bool, default=False\n",
    "        Compuatations using jax.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    rotation_matrix: np.array(shape=(3,3,...)),\n",
    "        A rotation matrix. If angle is a numpy array additional dimensions are stacked at the end.\n",
    "        \n",
    "    References\n",
    "    ----------\n",
    "    [1] https://en.wikipedia.org/wiki/Euler%E2%80%93Rodrigues_formula\n",
    "    [2] https://stackoverflow.com/questions/6802577/rotation-of-3d-vector\n",
    "    \"\"\"\n",
    "    _np = jnp if use_jax else np\n",
    "    \n",
    "    axis = _np.array(axis)\n",
    "    axis = axis / _np.sqrt(_np.dot(axis, axis))\n",
    "    \n",
    "    a = _np.cos(angle / 2.0)\n",
    "    b, c, d = _np.stack([-ax * _np.sin(angle / 2.0) for ax in axis])\n",
    "    aa, bb, cc, dd = a * a, b * b, c * c, d * d\n",
    "    bc, ad, ac, ab, bd, cd = b * c, a * d, a * c, a * b, b * d, c * d\n",
    "    return _np.array([[aa + bb - cc - dd, 2 * (bc + ad), 2 * (bd - ac)],\n",
    "                      [2 * (bc - ad), aa + cc - bb - dd, 2 * (cd + ab)],\n",
    "                      [2 * (bd + ac), 2 * (cd - ab), aa + dd - bb - cc]])\n",
    "\n",
    "def expand_dims(x, ndim, axis=0, use_jax=False):\n",
    "    _np = jnp if use_jax else np\n",
    "    for i in range(ndim-_np.array(x).ndim):\n",
    "        x = _np.expand_dims(x, axis=min(axis, _np.array(x).ndim))\n",
    "    return x\n",
    "\n",
    "def posenc(x, deg):\n",
    "    \"\"\"\n",
    "    Concatenate `x` with a positional encoding of `x` with degree `deg`.\n",
    "    Instead of computing [sin(x), cos(x)], we use the trig identity\n",
    "    cos(x) = sin(x + pi/2) and do one vectorized call to sin([x, x+pi/2]).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: jnp.ndarray, \n",
    "        variables to be encoded. Note that x should be in [-pi, pi].\n",
    "    deg: int, \n",
    "        the degree of the encoding.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    encoded: jnp.ndarray, \n",
    "        encoded variables.\n",
    "    \"\"\"\n",
    "    if deg == 0:\n",
    "        return x\n",
    "    scales = jnp.array([2**i for i in range(deg)])\n",
    "    xb = jnp.reshape((x[..., None, :] * scales[:, None]),\n",
    "                     list(x.shape[:-1]) + [-1])\n",
    "    four_feat = safe_sin(jnp.concatenate([xb, xb + 0.5 * jnp.pi], axis=-1))\n",
    "    return jnp.concatenate([x] + [four_feat], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c05ce135-73a2-49c6-aefd-a5e167b40bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Visualization methods -- needs debugging\n",
    "\"\"\"\n",
    "class VolumeVisualizer(object):\n",
    "    def __init__(self, width, height, samples):\n",
    "        \"\"\"\n",
    "        A Volume visualization class\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        width: int\n",
    "            camera horizontal resolution.\n",
    "        height: int\n",
    "            camera vertical resolution.\n",
    "        samples: int\n",
    "            Number of integration points along a ray.\n",
    "        \"\"\"\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.samples = samples \n",
    "        self.focal = .5 * width / jnp.tan(.5 * 0.7)\n",
    "        self._pts = None\n",
    "        \n",
    "    def set_view(self, radius, azimuth, zenith, up=np.array([0., 0., 1.])):\n",
    "        \"\"\"\n",
    "        Set camera view geometry\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        radius: float,\n",
    "            Distance from the origin\n",
    "        azimuth: float, \n",
    "            Azimuth angle in radians\n",
    "        zenith: float, \n",
    "            Zenith angle in radians\n",
    "        up: array, default=[0,0,1]\n",
    "            The up direction determines roll of the camera\n",
    "        \"\"\"\n",
    "        camorigin = radius * np.array([np.cos(azimuth)*np.sin(zenith), \n",
    "                                       np.sin(azimuth)*np.sin(zenith), \n",
    "                                       np.cos(zenith)])\n",
    "        self._viewmatrix = self.viewmatrix(camorigin, up, camorigin)\n",
    "        rays_o, rays_d = self.generate_rays(\n",
    "            self._viewmatrix, self.width, self.height, self.focal)\n",
    "        self._pts = self.sample_along_rays(rays_o, rays_d, 15., 35., self.samples)\n",
    "        self.x, self.y, self.z = self._pts[...,0], self._pts[...,1], self._pts[...,2]\n",
    "        self.d = jnp.linalg.norm(jnp.concatenate([jnp.diff(self._pts, axis=2), \n",
    "                                                  jnp.zeros_like(self._pts[...,-1:,:])], \n",
    "                                                 axis=2), axis=-1)\n",
    "    \n",
    "    def render(self, emission, facewidth, jit=False, bh_radius=0.0, linewidth=0.1, bh_albedo=[0,0,0], cmap='hot'):\n",
    "        \"\"\"\n",
    "        Render an image of the 3D emission\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        emission: 3D array \n",
    "            3D array with emission values\n",
    "        jit: bool, default=False,\n",
    "            Just in time compilation. Set true for rendering multiple frames.\n",
    "            First rendering will take more time due to compilation.\n",
    "        bh_radius: float, default=0.0\n",
    "            Radius at which to draw a black hole (for visualization). \n",
    "            If bh_radius=0 then no black hole is drawn.\n",
    "        facewidth: float, default=10.0 \n",
    "            width of the enclosing cube face\n",
    "        linewidth: float, default=0.1\n",
    "            width of the cube lines\n",
    "        bh_albedo: list, default=[0,0,0]\n",
    "            Albedo (rgb) of the black hole. default is completly black.\n",
    "        cmap: str, default='hot'\n",
    "            Colormap for visualization\n",
    "        Returns\n",
    "        -------\n",
    "        rendering: array,\n",
    "            Rendered image\n",
    "        \"\"\"\n",
    "        if self._pts is None: \n",
    "            raise AttributeError('must set view before rendering')\n",
    "    \n",
    "        \n",
    "        cm = plt.get_cmap('hot') \n",
    "        emission_cm = cm(emission)\n",
    "        emission_cm = jnp.clip(emission_cm - 0.05, 0.0, 1.0)\n",
    "        emission_cm = jnp.concatenate([emission_cm[..., :3], emission[..., None] / jnp.amax(emission)], axis=-1)\n",
    "\n",
    "        if jit:\n",
    "            emission_cube = draw_cube_jit(emission_cm, self._pts, facewidth, linewidth)\n",
    "            if bh_radius > 0:\n",
    "                emission_cube = draw_bh_jit(emission_cube, self._pts, bh_radius, bh_albedo)\n",
    "        else:\n",
    "            emission_cube = draw_cube(emission_cm, self._pts, facewidth, linewidth)\n",
    "            if bh_radius > 0:\n",
    "                emission_cube = draw_bh(emission_cube, self._pts, bh_radius, bh_albedo)\n",
    "        rendering = alpha_composite(emission_cube, self.d, self._pts, bh_radius)\n",
    "        return rendering\n",
    "    \n",
    "    def viewmatrix(self, lookdir, up, position):\n",
    "        \"\"\"Construct lookat view matrix.\"\"\"\n",
    "        vec2 = normalize(lookdir)\n",
    "        vec0 = normalize(np.cross(up, vec2))\n",
    "        vec1 = normalize(np.cross(vec2, vec0))\n",
    "        m = np.stack([vec0, vec1, vec2, position], axis=1)\n",
    "        return m\n",
    "\n",
    "    def generate_rays(self, camtoworlds, width, height, focal):\n",
    "        \"\"\"Generating rays for all images.\"\"\"\n",
    "        x, y = np.meshgrid(  # pylint: disable=unbalanced-tuple-unpacking\n",
    "            np.arange(width, dtype=np.float32),  # X-Axis (columns)\n",
    "            np.arange(height, dtype=np.float32),  # Y-Axis (rows)\n",
    "            indexing='xy')\n",
    "        camera_dirs = np.stack(\n",
    "            [(x - width * 0.5 + 0.5) / focal,\n",
    "             -(y - height * 0.5 + 0.5) / focal, -np.ones_like(x)],\n",
    "            axis=-1)\n",
    "        directions = ((camera_dirs[..., None, :] *\n",
    "                       camtoworlds[None, None, :3, :3]).sum(axis=-1))\n",
    "        origins = np.broadcast_to(camtoworlds[None, None, :3, -1],\n",
    "                                  directions.shape)\n",
    "\n",
    "        return origins, directions\n",
    "\n",
    "    def sample_along_rays(self, rays_o, rays_d, near, far, num_samples):\n",
    "        t_vals = jnp.linspace(near, far, num_samples)\n",
    "        pts = rays_o[..., None, :] + t_vals[None, None, :, None] * rays_d[..., None, :]\n",
    "        return pts\n",
    "    \n",
    "    @property\n",
    "    def coords(self):\n",
    "        coords = None if self._pts is None else jnp.moveaxis(self._pts, -1, 0)\n",
    "        return coords\n",
    "\n",
    "def alpha_composite(emission, dists, pts, bh_rad, inside_halfwidth=4.5):\n",
    "    emission = np.clip(emission, 0., 1.)\n",
    "    color = emission[..., :-1] * dists[0, ..., None]\n",
    "    alpha = emission[..., -1:] \n",
    "\n",
    "    # mask for points inside wireframe\n",
    "    inside = np.where(np.less(np.amax(np.abs(pts), axis=-1), inside_halfwidth), \n",
    "                      np.ones_like(pts[..., 0]),\n",
    "                      np.zeros_like(pts[..., 0]))\n",
    "\n",
    "    # masks for points outside black hole\n",
    "    bh = np.where(np.greater(np.linalg.norm(pts, axis=-1), bh_rad),\n",
    "                  np.ones_like(pts[..., 0]),\n",
    "                  np.zeros_like(pts[..., 0]))\n",
    "\n",
    "    combined_mask = np.logical_and(inside, bh)\n",
    "\n",
    "\n",
    "    rendering = np.zeros_like(color[:, :, 0, :])\n",
    "    acc = np.zeros_like(color[:, :, 0, 0])\n",
    "    outside_acc = np.zeros_like(color[:, :, 0, 0])\n",
    "    for i in range(alpha.shape[-2]):\n",
    "        ind = alpha.shape[-2] - i - 1\n",
    "\n",
    "        # if pixels inside cube and outside black hole, don't alpha composite\n",
    "        rendering = rendering + combined_mask[..., ind, None] * color[..., ind, :]\n",
    "\n",
    "        # else, alpha composite      \n",
    "        outside_alpha = alpha[..., ind, :] * (1. - combined_mask[..., ind, None])\n",
    "        rendering = rendering * (1. - outside_alpha) + color[..., ind, :] * outside_alpha \n",
    "\n",
    "        acc = alpha[..., ind, 0] + (1. - alpha[..., ind, 0]) * acc\n",
    "        outside_acc = outside_alpha[..., 0] + (1. - outside_alpha[..., 0]) * outside_acc\n",
    "\n",
    "    rendering += np.array([1., 1., 1.])[None, None, :] * (1. - acc[..., None])\n",
    "    return rendering\n",
    "\n",
    "@jax.jit\n",
    "def draw_cube_jit(emission_cm, pts, facewidth, linewidth):\n",
    "    \n",
    "    linecolor = jnp.array([0.0, 0.0, 0.0, 1000.0])\n",
    "    vertices = jnp.array([[-facewidth/2., -facewidth/2., -facewidth/2.],\n",
    "                        [facewidth/2., -facewidth/2., -facewidth/2.],\n",
    "                        [-facewidth/2., facewidth/2., -facewidth/2.],\n",
    "                        [facewidth/2., facewidth/2., -facewidth/2.],\n",
    "                        [-facewidth/2., -facewidth/2., facewidth/2.],\n",
    "                        [facewidth/2., -facewidth/2., facewidth/2.],\n",
    "                        [-facewidth/2., facewidth/2., facewidth/2.],\n",
    "                        [facewidth/2., facewidth/2., facewidth/2.]])\n",
    "    dirs = jnp.array([[-1., 0., 0.],\n",
    "                      [1., 0., 0.],\n",
    "                      [0., -1., 0.],\n",
    "                      [0., 1., 0.],\n",
    "                      [0., 0., -1.],\n",
    "                      [0., 0., 1.]])\n",
    "\n",
    "    for i in range(vertices.shape[0]):\n",
    "\n",
    "        for j in range(dirs.shape[0]):\n",
    "            # Draw line segments from each vertex\n",
    "            line_seg_pts = vertices[i, None, :] + jnp.linspace(0.0, facewidth, 64)[:, None] * dirs[j, None, :]\n",
    "\n",
    "            for k in range(line_seg_pts.shape[0]):\n",
    "                dists = jnp.linalg.norm(pts - jnp.broadcast_to(line_seg_pts[k, None, None, None, :], pts.shape), axis=-1)\n",
    "                emission_cm += linecolor[None, None, None, :] * jnp.exp(-1. * dists / linewidth ** 2)[..., None]\n",
    "\n",
    "    out = jnp.where(jnp.greater(jnp.broadcast_to(jnp.amax(jnp.abs(pts), axis=-1, keepdims=True), emission_cm.shape), \n",
    "                                facewidth/2. + linewidth), jnp.zeros_like(emission_cm), emission_cm)\n",
    "    return out\n",
    "\n",
    "def draw_cube(emission_cm, pts, facewidth, linewidth):\n",
    "    linecolor = jnp.array([0.0, 0.0, 0.0, 1000.0])\n",
    "    vertices = jnp.array([[-facewidth/2., -facewidth/2., -facewidth/2.],\n",
    "                        [facewidth/2., -facewidth/2., -facewidth/2.],\n",
    "                        [-facewidth/2., facewidth/2., -facewidth/2.],\n",
    "                        [facewidth/2., facewidth/2., -facewidth/2.],\n",
    "                        [-facewidth/2., -facewidth/2., facewidth/2.],\n",
    "                        [facewidth/2., -facewidth/2., facewidth/2.],\n",
    "                        [-facewidth/2., facewidth/2., facewidth/2.],\n",
    "                        [facewidth/2., facewidth/2., facewidth/2.]])\n",
    "    dirs = jnp.array([[-1., 0., 0.],\n",
    "                      [1., 0., 0.],\n",
    "                      [0., -1., 0.],\n",
    "                      [0., 1., 0.],\n",
    "                      [0., 0., -1.],\n",
    "                      [0., 0., 1.]])\n",
    "\n",
    "    for i in range(vertices.shape[0]):\n",
    "\n",
    "        for j in range(dirs.shape[0]):\n",
    "            # Draw line segments from each vertex\n",
    "            line_seg_pts = vertices[i, None, :] + jnp.linspace(0.0, facewidth, 64)[:, None] * dirs[j, None, :]\n",
    "\n",
    "            for k in range(line_seg_pts.shape[0]):\n",
    "                dists = jnp.linalg.norm(pts - jnp.broadcast_to(line_seg_pts[k, None, None, None, :], pts.shape), axis=-1)\n",
    "                emission_cm += linecolor[None, None, None, :] * jnp.exp(-1. * dists / linewidth ** 2)[..., None]\n",
    "\n",
    "    out = jnp.where(jnp.greater(jnp.broadcast_to(jnp.amax(jnp.abs(pts), axis=-1, keepdims=True), emission_cm.shape), \n",
    "                                facewidth/2. + linewidth), jnp.zeros_like(emission_cm), emission_cm)\n",
    "    return out\n",
    "\n",
    "@jax.jit\n",
    "def draw_bh_jit(emission, pts, bh_radius, bh_albedo):\n",
    "    bh_albedo = jnp.array(bh_albedo)[None, None, None, :]\n",
    "    lightdir = jnp.array([-1., -1., 1.])\n",
    "    lightdir /= jnp.linalg.norm(lightdir, axis=-1, keepdims=True)\n",
    "    bh_color = jnp.sum(lightdir * pts, axis=-1)[..., None] * bh_albedo\n",
    "    emission = jnp.where(jnp.less(jnp.linalg.norm(pts, axis=-1, keepdims=True), bh_radius),\n",
    "                    jnp.concatenate([bh_color, jnp.ones_like(emission[..., 3:])], axis=-1), emission)\n",
    "    return emission\n",
    "\n",
    "def draw_bh(emission, pts, bh_radius, bh_albedo):\n",
    "    bh_albedo = jnp.array(bh_albedo)[None, None, None, :]\n",
    "    lightdir = jnp.array([-1., -1., 1.])\n",
    "    lightdir /= jnp.linalg.norm(lightdir, axis=-1, keepdims=True)\n",
    "    bh_color = jnp.sum(lightdir * pts, axis=-1)[..., None] * bh_albedo\n",
    "    emission = jnp.where(jnp.less(jnp.linalg.norm(pts, axis=-1, keepdims=True), bh_radius),\n",
    "                    jnp.concatenate([bh_color, jnp.ones_like(emission[..., 3:])], axis=-1), emission)\n",
    "    return emission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2118c19-fccf-405c-897b-90e72a89a62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = '../checkpoints/tutorial3/recovery.2022-11-16.16:19:12/'\n",
    "predictor = NeRF_Predictor()\n",
    "state = checkpoints.restore_checkpoint(checkpoint_dir, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33fe4359-b3d1-4901-98c1-99b5d4e390a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define a VolumeVisualizer object\n",
    "\"\"\"\n",
    "resolution = 128\n",
    "visualizer = VolumeVisualizer(resolution, resolution, resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ae2f8a17-9643-49a9-bf37-fc3563f65669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a54ffa4dee048ed905fa411b282dce1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define the position of the camera and sample/integrate emission according to the camera rays.\n",
    "View the estimated emission at t=0 from multiple angles. \n",
    "Note that jit is useful for acceleration however the initial rendering will be slow due to compilation.\n",
    "\"\"\"\n",
    "images = []\n",
    "bh_radius = 2.0\n",
    "norm_const = 0.02\n",
    "rmax = 8.0\n",
    "\n",
    "for azimuth in tqdm(np.linspace(0.0, 360, 6)):\n",
    "    visualizer.set_view(radius=32.5, azimuth=azimuth, zenith=np.pi/3)\n",
    "    emission = sample_3d_grid(predictor.apply, state['params'], bh_radius, rmax, coords=visualizer.coords)\n",
    "    emission = emission / emission.max()\n",
    "    images.append(visualizer.render(emission, facewidth=2*rmax, jit=True, bh_radius=bh_radius))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "edd5d918-1edc-473d-b89d-9cc4db729490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d344671c38ec4ca091003e4082ed9542",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "fig, axes = plt.subplots(1, 6, figsize=(10,2))\n",
    "for ax, image in zip(axes, images):\n",
    "    ax.imshow(image);\n",
    "    ax.axis('off');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1ce7ec22-95be-4e12-b511-8741ad2c7873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aecc8953b5f4d3cbfe4bcd8dbeece80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=45.0, position=(0.0, -2.1650635094610964, 1.250000000000000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipyvolume as ipv\n",
    "emission = sample_3d_grid(predictor.apply, state['params'], rmin=bh_radius, rmax=rmax, fov=2*rmax)\n",
    "ipv.figure()\n",
    "ipv.view(0, -60, distance=2.5)\n",
    "ipv.volshow(emission, extent=[(-rmax, rmax)]*3, memorder='F', level=[0, 0.2, 0.7], opacity=[0, 0.2, 0.3], controls=False)\n",
    "ipv.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
