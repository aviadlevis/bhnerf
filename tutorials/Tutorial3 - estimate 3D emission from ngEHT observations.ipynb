{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89ca7d61-9108-47e2-90b0-b589975a9040",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tutorial3:estimate 3D emission from ngEHT observations\n",
    "\n",
    "---\n",
    "This tutorial demonstrates the recovery of 3D emission from ngEHT observations. The visibility meaurements are used to fit the parameters of a coordinate-based neural network and the rotation axis (dictated by the inclination angle). This tutorial assumes a sensor is ready to be loaded (see Tutorial1 for more details)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85f8e98-8ea4-4e4c-9304-038107b539e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-yjzw_9lz because the default path (/home/jovyan/.cache/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to eht-imaging! v 1.2.2 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-02 14:58:20.298934: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /.singularity.d/libs\n"
     ]
    }
   ],
   "source": [
    "import bhnerf\n",
    "from bhnerf.network import flattened_traversal, shard\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import ehtim as eh\n",
    "from ehtim.observing.obs_helpers import ftmatrix\n",
    "\n",
    "import jax\n",
    "import functools\n",
    "from jax import jit\n",
    "from jax import numpy as jnp\n",
    "import flax\n",
    "from flax.training import train_state\n",
    "from flax.training import checkpoints\n",
    "import optax\n",
    "\n",
    "from tensorboardX import SummaryWriter\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f70ecb40-d77f-4d00-b69d-8a375a3dcee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Producing clean visibilities from movie with direct FT . . . \n",
      "Applying Jones Matrices to data . . . \n",
      "Applying Jones Matrices to data . . . \n",
      "Adding thermal noise to data . . . \n",
      "Applying a priori calibration with estimated Jones matrices . . . \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Generate synthetic ngEHT observations of an orbiting Gaussian hotspot. \n",
    "This cell is condensed version of Tutorial 2.\n",
    "This notebook requires eht-imaging: https://github.com/achael/eht-imaging\n",
    "\"\"\"\n",
    "spatial_res = (64, 64, 64)\n",
    "nt = 128\n",
    "r_isco = 3.0\n",
    "orbit_radius = 3.5 \n",
    "std = .4\n",
    "rot_angle = 0\n",
    "rot_axis = [-0.5, 0.0, 0.8660254]\n",
    "orbit_period = orbit_radius**(-3./2.) \n",
    "velocity_field = lambda r: (1.0 / orbit_period) * r**(-3/2)\n",
    "\n",
    "initial_frame = bhnerf.emission.generate_hotspot_xr(spatial_res, rot_axis, rot_angle, orbit_radius, std, r_isco)\n",
    "emission = bhnerf.emission.generate_orbit(initial_frame, nt, velocity_field, rot_axis)\n",
    "\n",
    "# Normalize emission values \n",
    "normalization_factor = 0.02\n",
    "emissions = emission * normalization_factor\n",
    "\n",
    "# Load a precomuted sensor Dataset and integrate over the 4D emission field to get 3D image-plane movie.\n",
    "sensor = xr.load_dataset('../sensors/a0.00_th1.57_ngeo100_npix4096.nc')\n",
    "sensor = sensor.where(sensor.r < 5)\n",
    "sensor.attrs.update(r_min=sensor.r.min().data, r_max=sensor.r.max().data)\n",
    "sensor = sensor.fillna(0.0)\n",
    "image_pixels = bhnerf.emission.integrate_rays(emission, sensor)\n",
    "image_plane = image_pixels.data.reshape(nt, sensor.num_alpha, sensor.num_beta)\n",
    "\n",
    "\n",
    "# Generate synthetic ngEHT observations of the image plane.\n",
    "fov = 85.0             \n",
    "obs_params = {\n",
    "    'mjd': 57851,\n",
    "    'array': eh.array.load_txt('../eht_arrays/ngEHT.txt'),\n",
    "    'timetype': 'GMST',\n",
    "    'nt': 128,           # number of time samples \n",
    "    'tstart': 2.0,       # start of observations\n",
    "    'tstop': 2.0 + 2/3,  # end of observation \n",
    "    'tint': 15.0         # integration time\n",
    "}\n",
    "obs_empty = bhnerf.observation.empty_eht_obs(**obs_params)\n",
    "obs_args = {\n",
    "    'psize': fov / sensor.num_alpha * eh.ehc.RADPERUAS,\n",
    "    'ra': obs_empty.ra, \n",
    "    'dec': obs_empty.dec,\n",
    "    'rf': obs_empty.rf, \n",
    "    'mjd': obs_empty.mjd,\n",
    "}\n",
    "times = np.linspace(obs_params['tstart'], obs_params['tstop'], obs_params['nt'])\n",
    "movie = eh.movie.Movie(image_plane, times=times, **obs_args)\n",
    "obs = bhnerf.observation.observe_same(movie, obs_empty, ttype='direct', seed=None)\n",
    "\n",
    "# Stack measurements and associated parameters for down-stream optimization\n",
    "measurements = bhnerf.observation.padded_obs(obs, 'vis', fill_value=0.0)\n",
    "sigma = bhnerf.observation.padded_obs(obs, 'sigma', fill_value=np.inf)\n",
    "uv = np.stack((bhnerf.observation.padded_obs(obs, 'u'), bhnerf.observation.padded_obs(obs, 'v')), axis=2)\n",
    "ft_mats = np.nan_to_num(np.stack([ftmatrix(movie.psize, movie.xdim, movie.ydim, uv_t, pulse=movie.pulse) for uv_t in uv]), 0.0)\n",
    "obs_times = np.array([np.mean(obsdata['time'][0]) for obsdata in obs.tlist()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "592af2b4-cb10-4763-ade4-a05c95dc95ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "785f1a7a78ca40e8ae59ce4c893304e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.animation.FuncAnimation at 0x7f5f50761670>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Visualize the underlying image plane\n",
    "\"\"\"\n",
    "%matplotlib widget\n",
    "image_plane_xr = xr.DataArray(image_plane, dims=['t', 'alpha', 'beta'])\n",
    "image_plane_xr.visualization.animate(cmap='afmhot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca3de960-c15e-45f6-bc82-835019930c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Define the forward operator (generate synthetic ngEHT measurements), loss function and training step.\n",
    "\"\"\"\n",
    "axis_init = jnp.array([-0.4556, 0.5549, 0.6961])  # Randomly sampled (kept fixed for experiments)\n",
    "orbit_args = {\n",
    "    'tstart': obs_times[0], \n",
    "    'tstop': obs_times[-1],\n",
    "    'axis_init': axis_init,\n",
    "    'velocity': velocity_field \n",
    "}\n",
    "\n",
    "# Measurement model and loss/training setup\n",
    "predictor = bhnerf.network.NeRF_RotationAxis()\n",
    "emission_op = bhnerf.network.EmissionOperator(predictor, orbit_args)\n",
    "visibility_op = bhnerf.network.VisibilityOperator(emission_op)\n",
    "\n",
    "def loss_fn(params, coordinates, d, target, sigma, dtft_matrices):\n",
    "    visibilities, images = visibility_op(params, coordinates, d, dtft_matrices)\n",
    "    loss = jnp.mean((jnp.abs(visibilities - target)/sigma)**2)\n",
    "    return loss, [visibilities, images]\n",
    "\n",
    "@functools.partial(jit, static_argnums=(0))\n",
    "def train_step(loss_fn, state, x, y, z, t, d, target, sigma, dtft_matrices):\n",
    "    (loss, [visibilities, images]), grads = jax.value_and_grad(loss_fn, argnums=(0), has_aux=True)(\n",
    "        state.params, [t, x, y, z], d,  target, sigma, dtft_matrices)\n",
    "    grads = jax.lax.pmean(grads, axis_name='batch')\n",
    "    state = state.apply_gradients(grads=grads)\n",
    "    return loss, state, visibilities, images\n",
    "\n",
    "# Parallel mapping across GPUs\n",
    "train_pstep = jax.pmap(train_step, axis_name='batch', in_axes=(None, 0, 0, 0, 0, 0, 0, 0, 0, 0), static_broadcasted_argnums=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808d4541-e59e-4bc2-ac43-a59f256c464b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/imaging/projects/bh_nerf/envs/jax/lib/python3.9/site-packages/jax/lib/xla_bridge.py:390: UserWarning: jax.host_count has been renamed to jax.process_count. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n",
      "/scratch/imaging/projects/bh_nerf/envs/jax/lib/python3.9/site-packages/jax/lib/xla_bridge.py:377: UserWarning: jax.host_id has been renamed to jax.process_index. This alias will eventually be removed; please update your code.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600d76f541774f9c84b0d40e071041a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "iteration:   0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define training parameters and run the training loop.\n",
    "\"\"\"\n",
    "log_period = 100       # Logging frequency to TensorBoard\n",
    "save_period = 1000     # Saving checkpoints \n",
    "\n",
    "runname = 'tutorial3'\n",
    "checkpoint_dir = 'checkpoints/{}'.format(runname)\n",
    "logdir = 'runs/{}.{}'.format(runname, datetime.now().strftime('%Y-%m-%d.%H:%M:%S'))\n",
    "\n",
    "# Training params\n",
    "hparams = {\n",
    "    'num_iters': 5000,\n",
    "    'lr_init': 1e-4,\n",
    "    'lr_final': 1e-6,\n",
    "    'batchsize': 6,\n",
    "    'lr_axis': 1e-2,\n",
    "}\n",
    "\n",
    "# Define supervision coordinates\n",
    "t, x, y, z, d = bhnerf.network.get_input_coords(sensor, t_array=obs_times, batch='t').values()\n",
    "\n",
    "# Grid for visualization (no interpolation is added for easy comparison) \n",
    "vis_coords = np.meshgrid(orbit_args['tstart'], \n",
    "                         np.linspace(emission.x[0], emission.x[-1], spatial_res[0]),\n",
    "                         np.linspace(emission.y[0], emission.y[-1], spatial_res[1]),\n",
    "                         np.linspace(emission.z[0], emission.z[-1], spatial_res[2]),\n",
    "                         indexing='ij')\n",
    "\n",
    "params = predictor.init(jax.random.PRNGKey(1), [t[:1, ...], x[:1, ...], y[:1, ...], z[:1, ...]], **orbit_args)['params']\n",
    "\n",
    "# Split learning rate for axis / network parameters\n",
    "tx = optax.chain(optax.masked(optax.adam(learning_rate=hparams['lr_axis']), mask=flattened_traversal(lambda path, _: path[-1] == 'axis')),\n",
    "                 optax.masked(optax.adam(learning_rate=optax.polynomial_schedule(hparams['lr_init'], hparams['lr_final'], 1, hparams['num_iters'])),\n",
    "                              mask=flattened_traversal(lambda path, _: path[-1] != 'axis')))\n",
    "state = train_state.TrainState.create(apply_fn=predictor.apply, params=params.unfreeze(), tx=tx)  # TODO(pratul): this unfreeze feels sketchy\n",
    "\n",
    "# Restore saved checkpoint\n",
    "if np.isscalar(save_period): state = checkpoints.restore_checkpoint(checkpoint_dir, state)\n",
    "init_step = 1 + state.step\n",
    "\n",
    "state = flax.jax_utils.replicate(state) # For parallelization across GPUs\n",
    "\n",
    "# Training loop with TensorBoard logging \n",
    "with SummaryWriter(logdir=logdir) as writer:\n",
    "    \n",
    "    writer.add_images('emission/true', bhnerf.utils.intensity_to_nchw(emission.isel(t=0)), global_step=0)\n",
    "    \n",
    "    for i in tqdm(range(init_step, init_step + hparams['num_iters']), desc='iteration'):\n",
    "        batch_inds = np.random.choice(range(x.shape[0]), hparams['batchsize'], replace=False)\n",
    "        loss, state, visibilities, images = train_pstep(\n",
    "            loss_fn, state, shard(x[batch_inds, ...]), shard(y[batch_inds, ...]), shard(z[batch_inds, ...]), \n",
    "            shard(t[batch_inds, ...]), shard(d[batch_inds, ...]), shard(measurements[batch_inds, ...]), \n",
    "            shard(sigma[batch_inds, ...]), shard(ft_mats[batch_inds, ...])\n",
    "        )\n",
    "        \n",
    "        # Log the current state on TensorBoard\n",
    "        writer.add_scalar('log_loss/train', np.log10(np.mean(loss)), global_step=i)\n",
    "        if (i == 1) or (i % log_period) == 0:\n",
    "            current_state = jax.device_get(flax.jax_utils.unreplicate(state))\n",
    "            emission_grid = emission_op(current_state.params, vis_coords)\n",
    "            emission_grid = bhnerf.emission.zero_unsupervised_emission(emission_grid, vis_coords[1:], sensor.r_min, sensor.r_max)\n",
    "            rot_axis_estimate = bhnerf.utils.normalize(current_state.params['axis'])\n",
    "            writer.add_image('image_plane/true', image_plane[batch_inds[0], None, ...], global_step=i)\n",
    "            writer.add_image('image_plane/estimate', images[0, 0, None, :, :], global_step=i)\n",
    "            writer.add_images('emission/estimate', bhnerf.utils.intensity_to_nchw(emission_grid), global_step=i)\n",
    "            writer.add_scalar('emission/mse', bhnerf.utils.mse(emission.data[0], emission_grid), global_step=i)\n",
    "            writer.add_scalar('emission/psnr', bhnerf.utils.psnr(emission.data[0], emission_grid), global_step=i)\n",
    "            writer.add_scalar('rotation/dot_product', np.dot(rot_axis, rot_axis_estimate), global_step=i)\n",
    "        \n",
    "        # Save checkpoints occasionally\n",
    "        if np.isscalar(save_period) and ((i % save_period == 0) or (i == hparams['num_iters'])):\n",
    "            if (save_period % log_period): current_state = jax.device_get(flax.jax_utils.unreplicate(state))\n",
    "            checkpoints.save_checkpoint(checkpoint_dir, current_state, int(i), keep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ef13b84-4000-4e16-80ce-14554bf9bef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1341466b3a9945d0a8a4757a2f0c61d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Figure(camera=PerspectiveCamera(fov=45.0, position=(0.0, -2.1650635094610964, 1.250000000000000â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Visualization the recovered 3D emission estimated from ngEHT measurements.\n",
    "This visualization requires ipyvolume: https://ipyvolume.readthedocs.io/en/latest/\n",
    "\"\"\"\n",
    "import ipyvolume as ipv\n",
    "\n",
    "# Get the convereged solution from the neural network\n",
    "current_state = jax.device_get(flax.jax_utils.unreplicate(state))\n",
    "emission_grid = emission_op(current_state.params, vis_coords)\n",
    "emission_grid = bhnerf.emission.zero_unsupervised_emission(emission_grid, vis_coords[1:], sensor.r_min, sensor.r_max)\n",
    "        \n",
    "extent = [(float(emission[dim].min()), float(emission[dim].max())) for dim in ('x', 'y', 'z')]\n",
    "ipv.figure()\n",
    "ipv.view(0, -60, distance=2.5)\n",
    "ipv.volshow(emission_grid, extent=extent, memorder='F', level=[0, 0.2, 0.7], opacity=[0, 0.2, 0.3], controls=False)\n",
    "ipv.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jax",
   "language": "python",
   "name": "jax"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
